{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPHhgCEVDfJBIfgYd0EU9DR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shantanu2383/BALL_2015/blob/main/Accruals_in_the_Cross_Section.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6gujy73u4To",
        "outputId": "21e23b6e-d452-42d5-cebf-526706f765c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandasql\n",
            "  Downloading pandasql-0.7.3.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pandasql) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pandasql) (1.5.3)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (from pandasql) (2.0.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pandasql) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pandasql) (2022.7.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->pandasql) (2.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->pandasql) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->pandasql) (1.16.0)\n",
            "Building wheels for collected packages: pandasql\n",
            "  Building wheel for pandasql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandasql: filename=pandasql-0.7.3-py3-none-any.whl size=26784 sha256=a1684c6046f099b77a5509e2450f484265e59cd8320e9a6d9034623902237c99\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/bc/3a/8434bdcccf5779e72894a9b24fecbdcaf97940607eaf4bcdf9\n",
            "Successfully built pandasql\n",
            "Installing collected packages: pandasql\n",
            "Successfully installed pandasql-0.7.3\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import statsmodels.formula.api as smf \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install pandasql\n",
        "import os\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.arima_model import ARIMA \n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error \n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt \n",
        "from datetime import datetime\n",
        "import seaborn as sns \n",
        "import pandasql as ps\n",
        "\n",
        "from sqlite3 import connect\n",
        "conn=connect(':memory:')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataload"
      ],
      "metadata": {
        "id": "EdTRrMAuvJds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CRSP\n",
        "filepath=\"/content/gdrive/MyDrive/Accruals/\"\n",
        "\n",
        "file=\"CRSPMONTHLY.csv\"\n",
        "crsp=pd.read_csv(filepath + file)\n",
        "\n",
        "crsp['date'] = pd.to_datetime(crsp['date'], format=\"%Y%m%d\")\n",
        "\n",
        "\n",
        "crsp=crsp[(\"1960-01-01\"<=crsp['date']) & (crsp['date']< \"2019-01-01\")]\n",
        "crsp_parsed=crsp[['PERMNO', 'date', 'RET', 'SHROUT', 'ALTPRC', 'EXCHCD', 'SHRCD', 'SICCD', 'DLRET', 'DLSTCD', 'VOL']]\n",
        "crsp=crsp_parsed\n",
        "\n",
        "\n",
        "x=['PERMNO', 'RET', 'SHROUT', 'ALTPRC', 'EXCHCD', 'SHRCD', 'SICCD', 'DLRET', 'DLSTCD']\n",
        "\n",
        "for i in x:\n",
        "  crsp[i]=pd.to_numeric(crsp[i], errors='coerce')\n",
        "\n",
        "\n",
        "#convert returns to percent:\n",
        "crsp['RET']*=100\n",
        "crsp['DLRET']*=100\n",
        "\n",
        "\n",
        "#add market cap column\n",
        "crsp['mkt_cap']=abs(crsp['SHROUT'] * crsp['ALTPRC'])/1000\n",
        "crsp['mkt_cap'].replace(0, np.NaN, inplace=True)\n",
        "\n",
        "\n",
        "#ONLY KEEP US BASED COMMON STOCKS\n",
        "crsp=crsp[(crsp['SHRCD']==10)|(crsp['SHRCD']==11)]\n",
        "\n",
        "#rename variables to lower case\n",
        "crsp= crsp.rename(columns=str.lower)\n",
        "\n",
        "#filter for relevant exchanges\n",
        "exchange_mapping = {\n",
        "    1: 'NYSE', 31: 'NYSE',\n",
        "    2: 'AMEX', 32: 'AMEX',\n",
        "    3: 'NASDAQ', 33: 'NASDAQ'\n",
        "}\n",
        "#create dictionary to map values of the 'exchcd' column\n",
        "crsp['exchange'] = np.select(\n",
        "    [crsp['exchcd'].isin(exchange_mapping.keys()), crsp['exchcd'].notnull()],\n",
        "    [crsp['exchcd'].map(exchange_mapping), \"Other\"],\n",
        "    default='Other')\n",
        "\n",
        "\n",
        "#Adjust Returns\n",
        "crsp['ret_adj'] = crsp['ret']\n",
        "\n",
        "mask1 = pd.isnull(crsp['dlstcd'])\n",
        "crsp.loc[mask1, 'ret_adj'] = crsp.loc[mask1, 'ret']\n",
        "\n",
        "mask2 = pd.notnull(crsp['dlstcd']) & pd.notnull(crsp['dlret'])\n",
        "crsp.loc[mask2, 'ret_adj'] = crsp.loc[mask2, 'dlret']\n",
        "\n",
        "mask3 = ((551 <= crsp['dlstcd']) & (crsp['dlstcd'] <= 574)) | (crsp['dlstcd'].isin([500, 520, 580, 584]))\n",
        "crsp.loc[mask3, 'ret_adj'] = -30\n",
        "\n",
        "crsp.loc[~(mask1 | mask2 | mask3), 'ret_adj'] = -100\n",
        "\n",
        "crsp.drop(['shrcd', 'dlret', 'dlstcd'], inplace=True, axis=1)\n",
        "\n",
        "#exclude financial firms \n",
        "crsp=crsp[(crsp['siccd']<6000) |(crsp['siccd']>6999) ]\n",
        "\n",
        "\n",
        "#Add reference date for matching with Compustat\n",
        "\n",
        "crsp['date']=pd.to_datetime(crsp['date'])\n",
        "crsp['year']=crsp['date'].dt.year\n",
        "\n",
        "crsp['reference_date']=pd.to_datetime(crsp['year'].astype(str) +'-06-01')\n",
        "\n",
        "crsp.loc[crsp['date'].dt.month < 6, 'year'] -= 1\n",
        "\n",
        "crsp.loc[crsp['date'].dt.month < 6, 'reference_date'] = pd.to_datetime(\n",
        "    crsp['year'].astype(str) + '-06-01')\n",
        "\n",
        "crsp = crsp.drop('year', axis=1)\n",
        "\n",
        "crsp.set_index('date', inplace=True)\n",
        "\n",
        "crsp.sort_values(by=['date', 'permno'], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IL0qovjvKpk",
        "outputId": "73e30f72-12a9-4582-a0f8-5722aa9569e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-384bb7bc77a5>:5: DtypeWarning: Columns (5,6,9,18,19,38,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  crsp=pd.read_csv(filepath + file)\n",
            "<ipython-input-2-384bb7bc77a5>:72: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  crsp['date']=pd.to_datetime(crsp['date'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#COMPUSTAT\n",
        "filepath=\"/content/gdrive/MyDrive/Accruals/\"\n",
        "\n",
        "compustat=pd.read_csv(filepath + \"compustat.csv\")\n",
        "\n",
        "#Operating Profitability\n",
        "#REVT: Revenue\n",
        "#COGS: Cost of goods sold\n",
        "#XSGA-XRD: Reported sales, general and administrative expenses\n",
        "\n",
        "#Cash Based Operating Profitability\n",
        "#RECT: Accounts Recievable\n",
        "#INVT: Inventory\n",
        "#XPP: Prepaid Expenses\n",
        "#DRC + DRLT: Deferred Revenue\n",
        "#AP: Trade Accounts Payable\n",
        "#XACC: Accrued Expenses\n",
        "\n",
        "#CBOP-Alternate (Table 3)\n",
        "#RECCH: Decrease in accounts receivable\n",
        "#INVCH: Decrease in Inventory\n",
        "#APALCH: Increase in accounts payable and accrued liabilities\n",
        "\n",
        "#Accruals\n",
        "#ACT: Current Assets\n",
        "#CH: Cash\n",
        "#LCT: Current Liabilities\n",
        "#DLC: Debt in Current Liabilities\n",
        "#TXP: Income Taxes\n",
        "\n",
        "#Accruals-Alternate \n",
        "\n",
        "#RECCH: Decrease in accounts receivable\n",
        "#INVCH: Decrease in Inventory\n",
        "#APALCH: Increase in accounts payable and accrued liabilities\n",
        "#AOLOCH: Net change in other assets and liabilities\n",
        "#TXACH: Increase in accrued income taxes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnVMxD6VvQAl",
        "outputId": "72538390-8484-4177-9432-6e1d2b584ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-6ba830e62b2c>:4: DtypeWarning: Columns (2,15,17,18,19,23,24,29,33,37,952,953,955,956,957,962,976,977,982) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  compustat=pd.read_csv(filepath + \"compustat.csv\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compustat= compustat.rename(columns=str.lower)\n",
        "x=['gvkey', 'lpermno', 'datadate', 'linktype', 'linkenddt', 'seq', 'ceq',\n",
        "                    'at', 'lt', 'txditc', 'txdb', 'itcb', 'pstkrv', 'pstkl', 'pstk', 'indfmt', 'datafmt',\n",
        "                     'revt', 'cogs', 'xint', 'xsga', 'xrd', 'rect', 'invt', 'xpp', 'drc', 'drlt', 'ap', 'xacc',\n",
        "                      'cstk', 'caps', 'tstk', 're', 'acominc', 'mkvalt', 'act', 'ch', 'lct', 'dlc', 'txp', 'dp', 'gp',\n",
        "                        'recch', 'invch', 'apalch', 'aoloch', 'txach']\n",
        "\n",
        "compustat=compustat[x]\n",
        "\n",
        "\n",
        "dates=['datadate', 'linkenddt']\n",
        "for date in dates:\n",
        "  compustat[date]=pd.to_datetime(compustat[date], format=\"%Y%m%d\", errors='coerce')\n",
        "\n",
        "#filter columns\n",
        "compustat['datafmt']=compustat['datafmt'].apply(str)\n",
        "compustat=compustat[compustat[\"indfmt\"]==\"INDL\"]\n",
        "compustat=compustat[compustat['datafmt']==\"STD\"]\n",
        "\n",
        "#Only keep valid links\n",
        "compustat=compustat[(compustat[\"linktype\"]==\"LU\")| (compustat[\"linktype\"]==\"LC\")]\n",
        "\n",
        "#Only keep links active at datadate\n",
        "compustat=compustat[(compustat['datadate']<=compustat[\"linkenddt\"]) | pd.isnull(compustat['linkenddt'])]\n"
      ],
      "metadata": {
        "id": "hnBqBnDevSPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate book value using FF definition\n",
        "compustat.to_sql(\"compustat\", conn, if_exists='replace')\n",
        "\n",
        "query='''\n",
        "        SELECT DISTINCT *,\n",
        "        COALESCE(seq, ceq+pstk, at-lt) + COALESCE(txditc, txdb + itcb, 0)- COALESCE(pstkrv, pstkl, pstk, 0) as book_value\n",
        "        FROM compustat'''\n",
        "\n",
        "compustat_calc=pd.read_sql(query, conn)\n",
        "\n",
        "compustat=compustat_calc\n",
        "\n",
        "#add reference date for matching- We lag accounting information by 6 months,\n",
        "#therefore if a firms financial year ends in June, we assume this information is\n",
        "#available to investors the following June\n",
        "compustat['datadate']=pd.to_datetime(compustat['datadate'], errors='coerce')\n",
        "\n",
        "compustat['year']=compustat['datadate'].dt.year\n",
        "compustat['year']=pd.to_numeric(compustat['year'], errors='coerce')\n",
        "compustat['reference_date']=compustat['year']+1\n",
        "compustat['reference_date']=compustat['reference_date'].apply(str)\n",
        "compustat['reference_date']+=\"-06-01\"\n",
        "compustat['reference_date']=pd.to_datetime(compustat['reference_date'])"
      ],
      "metadata": {
        "id": "gQvm-2zRvS_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compustat.sort_values(by=['lpermno', 'datadate'], inplace=True)\n",
        "\n",
        "#Operating profitability calculation\n",
        "\n",
        "compustat['op']=compustat['revt']-compustat['cogs']-(compustat['xsga']-compustat['xrd'])\n",
        "\n",
        "#fill missing values with 0's\n",
        "for x in ['rect', 'invt', 'xpp', 'drc', 'drlt', 'ap', 'xacc', 'act', 'ch', 'lct', 'dlc', 'txp', 'dp']:\n",
        "  compustat[x]=compustat[x].fillna(0)\n",
        "\n",
        "\n",
        "#get lag of variables to calculate changes\n",
        "\n",
        "for x in ['rect', 'invt', 'xpp', 'drc', 'drlt', 'ap', 'xacc', 'act', 'ch', 'lct', 'dlc', 'txp', 'dp']:\n",
        "    compustat[f'{x}_lag1'] = compustat.groupby('lpermno')[x].shift(1)\n",
        "\n",
        "#calculate deltas\n",
        "for x in ['rect', 'invt', 'xpp', 'drc', 'drlt', 'ap', 'xacc', 'act', 'ch', 'lct', 'dlc', 'txp', 'dp']:\n",
        "  compustat[f'delta_{x}']=compustat[x]-compustat[f'{x}_lag1']\n",
        "\n",
        "\n",
        "#cash based operating profitability\n",
        "\n",
        "compustat['delta_dr']=compustat['delta_drc']+compustat['delta_drlt']\n",
        "\n",
        "compustat['cbop']=compustat['op']-compustat['delta_rect']-compustat['delta_invt']-compustat['delta_xpp']+compustat['delta_dr']+compustat['delta_ap']+compustat['delta_xacc']\n",
        "\n",
        "#accruals\n",
        "compustat['accruals']=compustat['delta_act']-compustat['delta_ch']-(compustat['delta_lct']-compustat['delta_dlc']-compustat['delta_txp'])-compustat['dp']\n",
        "\n",
        "#cash based operating profitability alternate calculation\n",
        "compustat['cbop_alternate']=compustat['op']+compustat['recch']+compustat['invch']+compustat['apalch']\n",
        "\n",
        "#accruals alternate calculation\n",
        "compustat['accruals_alternate']=-(compustat['recch'])-compustat['invch']-compustat['apalch']-compustat['aoloch']-compustat['txach']"
      ],
      "metadata": {
        "id": "lkkkCxZTvWFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compustat.rename(columns={'lpermno':'permno'}, inplace=True)\n",
        "#compustat.drop('index', axis=1, inplace=True)\n",
        "\n",
        "#compustat.rename(columns={'da_a/t-1': 'da_a_t_1'}, inplace=True)\n",
        "#crsp.drop(['level_0'],axis=1, inplace=True)\n",
        "crsp.to_sql(\"crsp\", conn, if_exists='replace')\n",
        "compustat.to_sql(\"compustat\", conn, if_exists='replace')\n",
        "\n",
        "query='''\n",
        "        SELECT DISTINCT crsp.*, c.gvkey, c.seq, c.ceq, c.at, c.lt, \n",
        "        c.txditc, c.txdb, c.itcb, c.pstkrv, c.pstkl, c.pstk,\n",
        "        c.revt, c.cogs, c.xint, c.xsga, c.xrd, c.rect, c.invt,\n",
        "        c.xpp, c.drc, c.drlt, c.ap, c.xacc, c.cstk, c.caps, c.tstk,\n",
        "        c.re, c.acominc, c.mkvalt, c.book_value, c.op, c.cbop, c.accruals, c.gp, c.cbop_alternate, c.accruals_alternate\n",
        "        FROM crsp\n",
        "        LEFT JOIN compustat c\n",
        "        ON crsp.permno=c.permno\n",
        "        AND crsp.reference_date=c.reference_date\n",
        "        '''\n",
        "crsp_comp=pd.read_sql(query, conn)\n",
        "crsp=crsp_comp"
      ],
      "metadata": {
        "id": "AmrTQYXTvY2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crsp['date'] = pd.to_datetime(crsp['date'])\n",
        "me=crsp[(crsp['date'].dt.month==12)]\n",
        "me['reference_date']=(me['date'].dt.year) + 1\n",
        "me['reference_date']=me['reference_date'].apply(str)\n",
        "me['reference_date']+=\"-06-01\"\n",
        "me['reference_date']=pd.to_datetime(me['reference_date'])\n",
        "#me.drop(['level_0'], axis=1, inplace=True)\n",
        "me.to_sql('me', conn, if_exists='replace')\n",
        "\n",
        "query='''\n",
        "        SELECT DISTINCT permno, reference_date, mkt_cap as market_equity\n",
        "        FROM me\n",
        "        '''\n",
        "me=pd.read_sql(query, conn)\n",
        "\n",
        "\n",
        "crsp.to_sql('crsp', conn, if_exists='replace')\n",
        "me.to_sql('me', conn, if_exists='replace')\n",
        "\n",
        "query='''\n",
        "        SELECT DISTINCT crsp.*, me.market_equity\n",
        "        FROM crsp\n",
        "        LEFT JOIN me\n",
        "        ON crsp.permno=me.permno\n",
        "        AND crsp.reference_date=me.reference_date\n",
        "        '''\n",
        "crsp_me=pd.read_sql(query, conn)\n",
        "\n",
        "crsp=crsp_me"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilJtHLlQva-6",
        "outputId": "d9f7c03d-1cbd-4c7e-c81d-6b04e407727c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-844af77dffef>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  me['reference_date']=(me['date'].dt.year) + 1\n",
            "<ipython-input-10-844af77dffef>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  me['reference_date']=me['reference_date'].apply(str)\n",
            "<ipython-input-10-844af77dffef>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  me['reference_date']+=\"-06-01\"\n",
            "<ipython-input-10-844af77dffef>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  me['reference_date']=pd.to_datetime(me['reference_date'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get prior month returns and 2-12 month returns\n",
        "\n",
        "columns=[]\n",
        "for x in range(1,13):\n",
        "  label=f\"return_t-{x}\"\n",
        "  columns.append(label)\n",
        "  crsp[f'return_t-{x}']=crsp.groupby('permno')['ret_adj'].shift(x)\n",
        "\n",
        "\n",
        "#2-12 month returns\n",
        "for x in range(2,13):\n",
        "  crsp[f'return_t-{x}']/=100\n",
        "  crsp[f'return_t-{x}']+=1\n",
        "\n",
        "crsp['return_t-2_t-12'] = np.cumprod(crsp.loc[:, 'return_t-2':'return_t-12'], axis=1).iloc[:, -1]\n",
        "\n",
        "# Subtract 1 and convert the result back to percentage returns\n",
        "crsp['return_t-2_t-12'] = (crsp['return_t-2_t-12'] - 1) * 100"
      ],
      "metadata": {
        "id": "mrVtnwU8ve96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sample Filters**"
      ],
      "metadata": {
        "id": "ySBmbdCjvvbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crsp['ret_adj'].isnull().sum()\n",
        "\n",
        "#filter sample\n",
        "crsp.dropna(subset=['market_equity'], inplace=True)\n",
        "crsp.dropna(subset=['book_value'], inplace=True)\n",
        "crsp.dropna(subset=['gp'], inplace=True)\n",
        "crsp.dropna(subset=['ret_adj'], inplace=True)\n",
        "\n",
        "#date filter\n",
        "crsp['date'] = pd.to_datetime(crsp['date'])  # Convert the 'date' column to Pandas Timestamp objects\n",
        "crsp = crsp[(crsp['date'] >= pd.to_datetime('1963-07-01')) & (crsp['date'] <= pd.to_datetime('2014-12-31'))]"
      ],
      "metadata": {
        "id": "6jRyOSB3vfe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Construct Variables**"
      ],
      "metadata": {
        "id": "rCOEkcEDvjOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scale variables by book value of total assets\n",
        "\n",
        "crsp['op_scaled']=crsp['op']/crsp['at']\n",
        "crsp['cbop_scaled']=crsp['cbop']/crsp['at']\n",
        "crsp['accruals_scaled']=crsp['accruals']/crsp['at']\n",
        "\n",
        "crsp['cbop_alternate_scaled']=crsp['cbop_alternate']/crsp['at']\n",
        "crsp['accruals_alternate_scaled']=crsp['accruals_alternate']/crsp['at']\n",
        "\n",
        "#book value variables\n",
        "crsp['book_to_market']=crsp['book_value']/crsp['market_equity']\n",
        "import numpy as np\n",
        "epsilon = 1e-8  # A small positive value to add to 'book_to_market' to avoid taking the logarithm of non-positive values\n",
        "crsp['log_book_to_market'] = np.log(crsp['book_to_market'] + epsilon)\n",
        "crsp['log_market_equity']=np.log(crsp['market_equity']+ epsilon)\n",
        "\n",
        "#return variables\n",
        "crsp['return_t-1']/=100\n",
        "crsp['return_t-2_t-12']/=100\n",
        "\n",
        "crsp.dropna(subset=['return_t-2_t-12'], inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "G2n9YtoOvmoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Table 5"
      ],
      "metadata": {
        "id": "znZBSuvtzOZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fama French Size Sort**"
      ],
      "metadata": {
        "id": "Fp9AL3kvz6z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crsp['date']=pd.to_datetime(crsp['date'])\n",
        "sb=crsp[(crsp['date'].dt.month==6) & (crsp['exchange']==\"NYSE\")]\n",
        "sb.to_sql('sb', conn, if_exists='replace')\n",
        "\n",
        "query='''\n",
        "        SELECT DISTINCT permno, reference_date, mkt_cap as ff_mkt_equity\n",
        "        FROM sb\n",
        "        '''\n",
        "\n",
        "sb=pd.read_sql(query, conn)\n"
      ],
      "metadata": {
        "id": "00RO1afC0B-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sb['median_mkt_cap'] = sb.groupby('reference_date')['ff_mkt_equity'].transform('median')\n",
        "\n",
        "sb.to_sql('sb', conn, if_exists='replace')\n",
        "\n",
        "query='''\n",
        "        SELECT DISTINCT reference_date, median_mkt_cap\n",
        "        FROM SB\n",
        "        '''\n",
        "sb=pd.read_sql(query, conn)\n"
      ],
      "metadata": {
        "id": "1FSsKBQo0GER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "crsp.to_sql('crsp', conn, if_exists='replace')\n",
        "sb.to_sql('sb', conn, if_exists='replace')\n",
        "query='''\n",
        "        SELECT DISTINCT crsp.*, sb.median_mkt_cap\n",
        "        FROM crsp\n",
        "        LEFT JOIN sb\n",
        "        ON crsp.reference_date=sb.reference_date\n",
        "        '''\n",
        "crsp_sb=pd.read_sql(query, conn)\n",
        "crsp=crsp_sb\n",
        "crsp.dropna(subset=['median_mkt_cap'], inplace=True)\n",
        "\n",
        "crsp['size_portfolio']=np.where(crsp['market_equity']>crsp['median_mkt_cap'], \"B\", \"S\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wfnVXV_B0WvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crsp['date']=pd.to_datetime(crsp['date'])\n",
        "bb=crsp[crsp['exchange']==\"NYSE\"]\n",
        "bb.drop('level_0', axis=1, inplace=True)\n",
        "bb.to_sql('bb', conn, if_exists='replace')\n",
        "\n",
        "query='''SELECT DISTINCT permno, reference_date, op_scaled, cbop_scaled, accruals_scaled\n",
        "          FROM bb\n",
        "          '''\n",
        "\n",
        "bb=pd.read_sql(query, conn)"
      ],
      "metadata": {
        "id": "xLPzon462JXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bb['op_30'] = bb.groupby('reference_date')['op_scaled'].transform(lambda x: x.quantile(0.3))\n",
        "bb['op_70'] = bb.groupby('reference_date')['op_scaled'].transform(lambda x: x.quantile(0.7))\n",
        "\n",
        "bb['cbop_30'] = bb.groupby('reference_date')['cbop_scaled'].transform(lambda x: x.quantile(0.3))\n",
        "bb['cbop_70'] = bb.groupby('reference_date')['cbop_scaled'].transform(lambda x: x.quantile(0.7))\n",
        "\n",
        "\n",
        "bb['accruals_30'] = bb.groupby('reference_date')['accruals_scaled'].transform(lambda x: x.quantile(0.3))\n",
        "bb['accruals_70'] = bb.groupby('reference_date')['accruals_scaled'].transform(lambda x: x.quantile(0.7))\n"
      ],
      "metadata": {
        "id": "6vdSDgP93t-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bb.to_sql('bb', conn, if_exists='replace')\n",
        "\n",
        "query='''\n",
        "        SELECT DISTINCT reference_date, op_30, op_70, cbop_30, cbop_70, accruals_30, accruals_70\n",
        "        FROM bb\n",
        "        '''\n",
        "\n",
        "bb=pd.read_sql(query, conn)\n",
        "\n"
      ],
      "metadata": {
        "id": "cnvuIsgB4Njn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#crsp.drop('level_0', axis=1, inplace=True)\n",
        "\n",
        "crsp.to_sql('crsp', conn, if_exists='replace')\n",
        "bb.to_sql('bb', conn, if_exists='replace')\n",
        "\n",
        "query='''\n",
        "        SELECT DISTINCT crsp.*, bb.op_30, bb.op_70, bb.cbop_30, bb.cbop_70, bb.accruals_30, bb.accruals_70\n",
        "        FROM crsp\n",
        "        LEFT JOIN bb\n",
        "        ON crsp.reference_date=bb.reference_date\n",
        "        '''\n",
        "crsp_bb=pd.read_sql(query, conn)\n",
        "crsp=crsp_bb"
      ],
      "metadata": {
        "id": "MygNfEKD4z0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crsp['op_portfolio'] = np.where(crsp['op_scaled'] < crsp['op_30'], 'weak', \n",
        "                               np.where(crsp['op_scaled'] > crsp['op_70'], 'robust', 'neutral'))\n",
        "\n",
        "\n",
        "crsp['cbop_portfolio'] = np.where(crsp['cbop_scaled'] < crsp['cbop_30'], 'weak', \n",
        "                               np.where(crsp['cbop_scaled'] > crsp['cbop_70'], 'robust', 'neutral'))\n",
        "\n",
        "crsp['accruals_portfolio'] = np.where(crsp['accruals_scaled'] < crsp['accruals_30'], 'weak', \n",
        "                               np.where(crsp['accruals_scaled'] > crsp['accruals_70'], 'robust', 'neutral'))\n"
      ],
      "metadata": {
        "id": "JelSH1Y07Rd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row_names = ['Average Annualized Return', 'Standard Deviation', 't-value']\n",
        "column_names = ['Mkt-RF', 'SMB', 'HML', 'UMD', 'ACC', 'RMW_OP', 'RMW_CBOP']\n",
        "\n",
        "table_5= pd.DataFrame(index=row_names, columns=column_names)"
      ],
      "metadata": {
        "id": "PFzaZbgaCwnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in zip(['op', 'cbop', 'accruals'], ['RMW_OP', 'RMW_CBOP', 'ACC']):\n",
        "  returns=crsp.groupby(['date', 'size_portfolio', f'{x}_portfolio']).apply(lambda x: np.average(pd.to_numeric(x['ret_adj']), weights=pd.to_numeric(x['market_equity'])))\n",
        "  returns=returns.to_frame().reset_index()\n",
        "  returns = returns.pivot(index='date', columns=['size_portfolio', f'{x}_portfolio'], values=0)\n",
        "\n",
        "  returns.columns = returns.columns.map('_'.join)\n",
        "  returns.reset_index(inplace=True)\n",
        "\n",
        "  if x=='accruals':\n",
        "    returns['HML'] = 0.5 * (returns['S_weak'] + returns['B_weak']) - 0.5 * (returns['S_robust'] + returns['B_robust'])\n",
        "  else:\n",
        "    returns['HML'] = 0.5 * (returns['S_robust'] + returns['B_robust']) - 0.5 * (returns['S_weak'] + returns['B_weak'])\n",
        "\n",
        "  hml=returns['HML'].mean()\n",
        "  hml/=100\n",
        "  annualized_average_return = ((1 + hml) ** 12) - 1\n",
        "  annualized_average_return=annualized_average_return*100\n",
        "\n",
        "  # Calculate the monthly decimal returns\n",
        "  returns['HML_decimal'] = returns['HML'] / 100 + 1\n",
        "\n",
        "  # Calculate the standard deviation of the monthly decimal returns\n",
        "  monthly_std_decimal = returns['HML_decimal'].std()\n",
        "\n",
        "  # Annualize the standard deviation\n",
        "  annualized_std_decimal = (monthly_std_decimal * np.sqrt(12))*100\n",
        "\n",
        "  import numpy as np\n",
        "\n",
        "  # Calculate the mean and standard deviation of HML\n",
        "  hml_mean = returns['HML'].mean()\n",
        "  hml_std = returns['HML'].std()\n",
        "\n",
        "  # Calculate the number of observations (N)\n",
        "  N = len(returns)\n",
        "\n",
        "  # Calculate the standard error of the mean\n",
        "  hml_standard_error = hml_std / np.sqrt(N)\n",
        "\n",
        "  # Calculate the t-statistic\n",
        "  hml_t_statistic = hml_mean / hml_standard_error\n",
        "\n",
        "  table_5.loc['Average Annualized Return', y] = annualized_average_return\n",
        "  table_5.loc['Standard Deviation', y] = annualized_std_decimal\n",
        "  table_5.loc['t-value', y] = hml_t_statistic\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aUr9BkUjDLKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_5=table_5.round(2)\n",
        "table_5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "RktlABS0HbQX",
        "outputId": "ca5edf9a-89c2-4104-c193-70a7546c42d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          Mkt-RF  SMB  HML  UMD       ACC    RMW_OP  RMW_CBOP\n",
              "Average Annualized Return    NaN  NaN  NaN  NaN   2.25494  3.637287  5.777456\n",
              "Standard Deviation           NaN  NaN  NaN  NaN  5.765567  9.508552  8.659726\n",
              "t-value                      NaN  NaN  NaN  NaN  2.753272  2.676286  4.623803"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef5c76d5-820b-491c-b9e6-515dbb9c2987\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mkt-RF</th>\n",
              "      <th>SMB</th>\n",
              "      <th>HML</th>\n",
              "      <th>UMD</th>\n",
              "      <th>ACC</th>\n",
              "      <th>RMW_OP</th>\n",
              "      <th>RMW_CBOP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Average Annualized Return</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.25494</td>\n",
              "      <td>3.637287</td>\n",
              "      <td>5.777456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Standard Deviation</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.765567</td>\n",
              "      <td>9.508552</td>\n",
              "      <td>8.659726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t-value</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.753272</td>\n",
              "      <td>2.676286</td>\n",
              "      <td>4.623803</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef5c76d5-820b-491c-b9e6-515dbb9c2987')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef5c76d5-820b-491c-b9e6-515dbb9c2987 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef5c76d5-820b-491c-b9e6-515dbb9c2987');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add in Standard Fama French Factors"
      ],
      "metadata": {
        "id": "6bdVfe4CV3jr"
      }
    }
  ]
}